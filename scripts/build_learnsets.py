"""
Handles generating learnset codetables which are packed into NARC subfiles via codetables.mk

Responsible for generating the following:
  data/generated/MachineMoveLearnsets.c
  data/generated/LevelupLearnsets.c
  data/generated/EggLearnsets.c
"""

import re
import json
import os
import argparse


def load_species_header(file_path):
    species_dict = {}
    index = 0
    with open(file_path) as f:
        for line in f:
            if len(line.split()) > 1:
                test = line.split()[1].strip()
                if 'SPECIES' in test and not '_START' in test and not '_SPECIES_H' in test and not '_NUM (' in line and not 'MAX_' in test:
                    species_dict[test] = index
                    index += 1
    return species_dict


def load_moves_header(file_path):
    moves_dict = {}
    index = 0
    with open(file_path) as f:
        for line in f:
            if len(line.split()) > 1:
                test = line.split()[1].strip()
                if 'MOVE' in test and not '_START' in test and not '_MOVES_H' in test and not 'NUM_OF' in test:
                    moves_dict[test] = index
                    index += 1
    return moves_dict


def load_machine_move_list(file_path):
    move_list = []
    in_array = False
    move_pattern = re.compile(r'\bMOVE_[A-Z0-9_]+')

    with open(file_path, encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if 'static const u16 sMachineMoves[]' in line:
                in_array = True
                continue
            if in_array:
                if '};' in line:
                    break
                matches = move_pattern.findall(line)
                move_list.extend(matches)

    return move_list


def write_learnset_constants_inc(max_num_levelup_moves, output_path):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, "w") as f:
        f.write("// DO NOT MODIFY THIS FILE! Autogenerated by build_learnsets.py\n\n")
        f.write(f"MAX_LEVELUP_MOVES equ {max_num_levelup_moves}")


def write_learnset_constants_header(num_machine_moves, max_num_levelup_moves, max_num_egg_moves, output_path):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, "w") as f:
        f.write("// DO NOT MODIFY THIS FILE! Autogenerated by build_learnsets.py\n\n")
        f.write("#ifndef GENERATED_LEARNSET_CONSTANTS_H\n")
        f.write("#define GENERATED_LEARNSET_CONSTANTS_H\n\n")
        f.write(f"#define NUM_MACHINE_MOVES {num_machine_moves}\n")
        f.write(f"#define MAX_LEVELUP_MOVES {max_num_levelup_moves}\n")
        f.write(f"#define MAX_EGG_MOVES     {max_num_egg_moves}\n\n")
        f.write(f"#define MACHINE_LEARNSETS_BITFIELD_COUNT ((NUM_MACHINE_MOVES + 31) / 32)\n\n")
        f.write("#endif // GENERATED_LEARNSET_CONSTANTS_H\n")


def write_machine_data(species_dict, moves_dict, species_learnsets, machine_moves, output_path):
    move_to_index = {
        move_name: idx
        for idx, move_name in enumerate(machine_moves)
        if move_name in moves_dict
    }

    max_species_index = max(species_dict.values())
    species_id_to_name = {v: k for k, v in species_dict.items()}

    with open(output_path, "w") as out:
        out.write("// DO NOT MODIFY THIS FILE!  autogenerated by build_learnsets.py\n\n")
        out.write("#include \"../../include/types.h\"\n")
        out.write("#include \"../../include/constants/species.h\"\n")
        out.write("#include \"../../include/constants/generated/learnsets.h\"\n\n")
        out.write(f"const u32 UNUSED MachineMoveLearnsets[][MACHINE_LEARNSETS_BITFIELD_COUNT] = {{\n")

        for species_id in range(max_species_index + 1):
            species_name = species_id_to_name.get(species_id)
            learnset = []
            if species_name:
                learnset = species_learnsets.get(species_name, {}).get("MachineMoves", [])
                learnset = list(set(m.strip() for m in learnset))

            parts = [0] * ((len(machine_moves) + 31) // 32)
            for move in learnset:
                move_index = move_to_index.get(move)
                if move_index is not None and move_index < len(machine_moves):
                    word = move_index // 32
                    bit = move_index % 32
                    parts[word] |= (1 << bit)

            formatted = ", ".join(f"0x{val:08X}" for val in parts)
            out.write(f"    [{species_name}] = {{ {formatted} }},\n")

        out.write("};\n")


def write_levelup_data(species_dict, moves_dict, species_learnsets, max_num_levelup_moves, output_path):
    species_id_to_name = {v: k for k, v in species_dict.items()}
    max_species_id = max(species_id_to_name.keys())
    col_len = 8

    with open(output_path, "w") as out:
        out.write("// DO NOT MODIFY THIS FILE! Autogenerated by build_learnsets.py\n\n")
        out.write("#include \"../../include/types.h\"\n")
        out.write("#include \"../../include/constants/generated/learnsets.h\"\n")
        out.write("#include \"../../include/constants/species.h\"\n\n")
        out.write("const u32 UNUSED LevelUpLearnsets[][MAX_LEVELUP_MOVES] = {\n")

        for species_id in range(max_species_id + 1):
            species_name = species_id_to_name.get(species_id)
            learnset = []
            if species_name:
                learnset = species_learnsets.get(species_name, {}).get("LevelMoves", [])

            entries = []

            for move_entry in learnset:
                move = move_entry.get("Move", "").strip()
                level = int(move_entry["Level"])
                if not move or move not in moves_dict:
                    print(f"[ERROR]: Invalid or missing move '{move}' for species '{species_name}' at level {level}")
                    exit(1)

                move_id = moves_dict[move]
                encoded = (level << 16) | move_id
                entries.append(encoded)

            entries.append(0x0000FFFF)
            while len(entries) < max_num_levelup_moves:
                entries.append(0x0000FFFF)

            out.write(f"    [{species_name}] = {{\n")
            for i in range(0, max_num_levelup_moves, col_len):
                line = ", ".join(f"0x{val:08X}" for val in entries[i:i+col_len])
                out.write(f"        {line},\n")
            out.write("    },\n")

        out.write("};\n")


def write_eggmove_data(species_dict, moves_dict, species_learnsets, max_num_egg_moves, output_path):
    species_id_to_name = {v: k for k, v in species_dict.items()}
    max_species_id = max(species_id_to_name)
    col_len = 12

    with open(output_path, "w") as out:
        out.write("// DO NOT MODIFY THIS FILE! Autogenerated by build_learnsets.py\n\n")
        out.write("#include \"../../include/types.h\"\n")
        out.write("#include \"../../include/constants/generated/learnsets.h\"\n")
        out.write("#include \"../../include/constants/species.h\"\n\n")
        out.write("const u16 UNUSED EggMoves[][MAX_EGG_MOVES] = {\n")

        for species_id in range(max_species_id + 1):
            species_name = species_id_to_name.get(species_id, "")
            egg_moves = []

            if species_name:
                egg_moves = species_learnsets.get(species_name, {}).get("EggMoves", [])

            moves = []
            for move in egg_moves:
                if move not in moves_dict:
                    print(f"[ERROR]: Move '{move}' not found in moves.h")
                    exit(1)
                moves.append(moves_dict[move])

            # Add terminator and pad to fixed length
            moves.append(0xFFFF)
            while len(moves) < max_num_egg_moves:
                moves.append(0xFFFF)

            out.write(f"    [{species_name}] = {{\n")
            for i in range(0, max_num_egg_moves, col_len):
                chunk = moves[i:i+col_len]
                out.write("        " + ", ".join(f"0x{m:04X}" for m in chunk) + ",\n")
            out.write("    },\n")

        out.write("};\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--learnsets", default="data/mon/learnsets.json")
    parser.add_argument("--machineout")
    parser.add_argument("--levelupout")
    parser.add_argument("--eggout")
    parser.add_argument("--constsout", action='store_true')
    args = parser.parse_args()

    machine_moves = load_machine_move_list("src/item.c")
    species_dict = load_species_header("include/constants/species.h")
    moves_dict = load_moves_header("include/constants/moves.h")

    with open(args.learnsets, encoding="utf-8") as f:
        species_learnsets = json.load(f)

    max_num_levelup_moves = max(
        (len(data.get("LevelMoves", [])) + 1)  # +1 for terminator
        for data in species_learnsets.values()
    )

    # move reminder limitation
    if max_num_levelup_moves > (256/4):
        print(f"[ERROR]: maximum number of level-up moves cannot exceed 64 ({max_num_levelup_moves})")
        exit(1)

    max_num_egg_moves = max(
        (len(data.get("EggMoves", [])) + 1)  # +1 for terminator
        for data in species_learnsets.values()
    )

    if args.constsout:
        write_learnset_constants_header(len(machine_moves), max_num_levelup_moves, max_num_egg_moves, "include/constants/generated/learnsets.h")
        write_learnset_constants_inc(max_num_levelup_moves, "armips/include/generated/levelup.s")

    if args.machineout:
        write_machine_data(species_dict, moves_dict, species_learnsets, machine_moves, args.machineout)

    if args.levelupout:
        write_levelup_data(species_dict, moves_dict, species_learnsets, max_num_levelup_moves, args.levelupout)

    if args.eggout:
        write_eggmove_data(species_dict, moves_dict, species_learnsets, max_num_egg_moves, args.eggout)
